# Pika port
port : 9221
# Thread Number
thread-num : 16
# Sync Thread Number
sync-thread-num : 6
# Item count of sync thread queue
sync-buffer-size : 10
# Pika and Rocksdb log path
log-path : ./log/
# Pika binlog path
binlog-path : ./binlog/
# Pika glog level: only INFO and ERROR
loglevel : info
# Pika glog size : default is 1800MB
max-log-size : 1024
# Pika db path
db-path : ./db/
# Pika write-buffer-size
write-buffer-size : 268435456
# Pika max-write-buffer-number, The default and the minimum number is 2
max-write-buffer-number : 2
# Pika timeout
timeout : 60
# InfoCmd fresh interval (s)
fresh-info-interval : 60
# Requirepass
requirepass :
# Masterauth
masterauth :
# Userpass
userpass :
# User Blacklist
userblacklist :
# Dump Prefix
dump-prefix :
# daemonize  [yes | no]
daemonize : yes
# slotmigrate  [yes | no]
slotmigrate : no
# slotmigrate thread num
slotmigrate-thread-num : 8
# thread-migrate-keys-num
thread-migrate-keys-num : 64
# Dump Path
dump-path : ./dump/
# Expire-dump-days
dump-expire : 3
# pidfile Path
pidfile : ./pika.pid
# Max Connection
maxclients : 20000
# the per file size of sst to compact, defalut is 2M
target-file-size-base : 20971520
# max_bytes_for_level_base is the max total for level-1, default is 256M
max-bytes-for-level-base : 268435456
# Expire-logs-days
expire-logs-days : 7
# Expire-logs-nums
expire-logs-nums : 100
# binlog_writer_queue_size is the max size for binlog_queue, default is 10000
binlog-writer-queue-size : 10000
# binlog_writer working mode: only sync and async.
binlog-writer-method : async
# Number of binlog-writer thread
binlog-writer-num : 4
# Root-connection-num
root-connection-num : 2
# slowlog-log-slower-than(us)
slowlog-log-slower-than : 100000
# slowlog-max-len
slowlog-max-len : 12800
# slowlog-token-capacity
slowlog-token-capacity : 100
#refill 100 tokens every second
slowlog-token-fill-every: 100
# slave-read-only(yes/no, 1/0)
slave-read-only : 0
# Pika db sync path
db-sync-path : ./dbsync/
# db sync speed(MB) max is set to 125MB, min is set to 0, and if below 0 or above 125, the value will be adjust to 125
db-sync-speed : -1
# The slave priority
slave-priority : 100
# network interface
# network-interface : eth1
# replication
# slaveof : master-ip:master-port
#
# CronTask, format: start-end/ratio, like 02-04/60, pika will check to schedule compaction between 2 to 4 o'clock everyday
#                   if the freesize/disksize > 60%.
compact-cron :
#
# Compact-interval, format: interval/ratio, like 6/60, pika will check to schedule compaction every 6 hours,
#                           if the freesize/disksize > 60%.
compact-interval :

###################
## Threadpool Settings
###################
# use-thread-pool [yes | no]
use-thread-pool : yes
# Fast thread pool size
fast-thread-pool-size : 16
# Slow thread pool size
slow-thread-pool-size : 16
# Slow cmd list
slow-cmd-list : 

###################
## Cache Settings
###################
# cache-num
cache-num : 16

# cache-model 0:cache_none 1:cache_read
cache-model : 0
# cache-type: string, set, zset, list, hash, bit
cache-type: zset
# cache-start-direction 0:cache first ${cache-items-per-key} items; -1:cache last ${cache-items-per-key} items
cache-start-direction : 0
cache-items-per-key : 512

# cache-maxmemory, unit bytes
cache-maxmemory : 10737418240

# cache-maxmemory-policy
# 0: volatile-lru -> Evict using approximated LRU among the keys with an expire set.
# 1: allkeys-lru -> Evict any key using approximated LRU.
# 2: volatile-lfu -> Evict using approximated LFU among the keys with an expire set.
# 3: allkeys-lfu -> Evict any key using approximated LFU.
# 4: volatile-random -> Remove a random key among the ones with an expire set.
# 5: allkeys-random -> Remove a random key, any key.
# 6: volatile-ttl -> Remove the key with the nearest expire time (minor TTL)
# 7: noeviction -> Don't evict anything, just return an error on write operations.
cache-maxmemory-policy : 1

# cache-maxmemory-samples
cache-maxmemory-samples: 5

# cache-lfu-decay-time
cache-lfu-decay-time: 1

########################
## Zset auto del setting
########################
# when the number of zset is more than the threshold, auto delete members. 0 means disable auto delete.
zset-auto-del-threshold : 0
# delete direction, 0 means delete from head, -1 means delete from tail.
zset-auto-del-direction : 0
# the number of deleted member
zset-auto-del-num : 1
# auto delete cron task, format: start-end, like 02-04, pika will check to schedule auto delete zset between 2 to 4 o'clock everyday
zset-auto-del-cron :
# auto delete interval, format: interval, like 6, pika will check to schedule auto delete zset every 6 hours.
zset-auto-del-interval : 0
# when delete a key members success, will sleep for a moment. sleep time = delete time * speed factor. you can set like 0.1 [0,1000]
zset-auto-del-cron-speed-factor : 0.1
# scan the number of keys from zset db at a time.
zset-auto-del-scan-round-num : 10000
# the ratio of how mutch deleted zset keys can trigger compact zset db, [0,1]
zset-compact-del-ratio : 1
# how mutch deleted zset keys num that can trigger compact zset db
zset-compact-del-num : 1000000000

###################
## Critical Settings
###################
# write_binlog  [yes | no]
write-binlog : yes
# binlog file size: default is 100M,  limited in [1K, 2G]
binlog-file-size : 104857600
# Compression
compression : snappy
# max-background-flushes: default is 2, limited in [1, 4]
max-background-flushes : 2
# max-background-compactions: default is 4, limited in [1, 8]
max-background-compactions : 4
# max-cache-files default is 5000
max-cache-files : 5000
# max_bytes_for_level_multiplier: default is 10, you can change it to 5
max-bytes-for-level-multiplier : 10
# Disable automatic compactions. Manual compactions can still be issued on this column family. (yes/no, 1/0)
disable-auto-compactions : no
# Number of files to trigger level-0 compaction, default is 4
level0-file-num-compaction-trigger : 4
# Pika level0-slowdown-writes-trigger, default is 20
level0-slowdown-writes-trigger : 20
# Pika level0-stop-writes-trigger, default is 32
level0-stop-writes-trigger : 32
# min-blob-size is the smallest value to store in blob files. Value smaller than this threshold will be inlined in base DB.
min-blob-size : 65536
# rate-bytes-per-sec controls the total write rate of compaction and flush in bytes per second. default is 50M, can not less than 1M.
rate-bytes-per-sec : 52428800
# if true, writes will not first go to the write rocksdb ahead log, and the write may got lost after a crash. [yes | no]
disable-wal : no
# Periodic compactions, Files older than this value will be picked up for compaction
periodic-compaction-seconds : 0
# If system free memory less than min-system-free-mem, clear system cached memory. 0 means disable clear cached memory. you can set like 1073741824(1G).
min-system-free-mem : 0
# The min gc batch size at one time. default is 536870912(512M)
min-gc-batch-size : 536870912
# The max gc batch size at one time. default is 1073741824(1G)
max-gc-batch-size : 1073741824
# The ratio of how much discardable size of a blob file can be GC. default is 50, means 50% file size can be GC.
blob-file-discardable-ratio : 50
# gc-sample-cycle default is 604800(7day)
gc-sample-cycle : 604800
# max-gc-queue-size default is 2
max-gc-queue-size : 2
# max-gc-file-count default is 1000
max-gc-file-count : 1000
# BlockBasedTable block_size, default 4k
# block-size: 4096
# block LRU cache, 0 to disable. you can set like 268435456(256M).
# block-cache: 0
# whether the block cache is shared among the RocksDB instances, default is per CF
# share-block-cache: no
# whether or not index and filter blocks is stored in block cache
# cache-index-and-filter-blocks: no
# when set to yes, bloomfilter of the last level will not be built
# optimize-filters-for-hits: no
# https://github.com/facebook/rocksdb/wiki/Leveled-Compaction#levels-target-size
# level-compaction-dynamic-level-bytes: no
# Break a compaction job into multiple, smaller ones
# max-subcompactions: 3
